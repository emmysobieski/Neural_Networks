{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34224</th>\n",
       "      <td>990087275</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF SHEET METAL AIR R...</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>11432603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34225</th>\n",
       "      <td>990140474</td>\n",
       "      <td>UNITED STATES PONY CLUBS INC</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34226</th>\n",
       "      <td>990165772</td>\n",
       "      <td>AMERICAN WATER WORKS ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1800</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>223007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34227</th>\n",
       "      <td>990187594</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>990187607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>N</td>\n",
       "      <td>17192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "34224  990087275  INTERNATIONAL ASSOCIATION OF SHEET METAL AIR R...   \n",
       "34225  990140474                       UNITED STATES PONY CLUBS INC   \n",
       "34226  990165772                   AMERICAN WATER WORKS ASSOCIATION   \n",
       "34227  990187594                                PTA HAWAII CONGRESS   \n",
       "34228  990187607                                PTA HAWAII CONGRESS   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "34224               T5  CompanySponsored          C3000    ProductDev   \n",
       "34225               T3  CompanySponsored          C1200  Preservation   \n",
       "34226               T3  CompanySponsored          C1800  Preservation   \n",
       "34227               T3  CompanySponsored          C2000  Preservation   \n",
       "34228               T3       Independent          C1000  Preservation   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "34224   Association       1          1M-5M                      N  11432603   \n",
       "34225   Association       1              0                      N      5000   \n",
       "34226   Association       1  100000-499999                      N    223007   \n",
       "34227   Association       1              0                      N      5000   \n",
       "34228         Trust       1    25000-99999                      N     17192   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "34224              0  \n",
       "34225              1  \n",
       "34226              1  \n",
       "34227              1  \n",
       "34228              0  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[75 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "charity_df = pd.read_csv(\"C:/Users/esobieski/Documents/Berkeley/Neural_Networks/charity_data.csv\")\n",
    "charity_df.tail(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat = charity_df.dtypes[charity_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "charity_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# SPECIAL_CONSIDERATIONS HAS 27 YES and 122 NO, KEEP AND TRANSFORM\n",
    "print(charity_df['SPECIAL_CONSIDERATIONS'].value_counts()['Y'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0   Association              0                      N     5000              1  \n",
       "1  Co-operative         1-9999                      N   108590              1  \n",
       "2   Association              0                      N     5000              0  \n",
       "3         Trust    10000-24999                      N     6692              1  \n",
       "4         Trust  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete columns:\n",
    "charity_df.drop(['STATUS', 'EIN', 'NAME'], axis=1, inplace=True)\n",
    "charity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our NEW categorical variable list\n",
    "charity_cat1 = charity_df.dtypes[charity_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "charity_df[charity_cat1].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare 2 columns (classification and application type) for bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in column APPLICATION_TYPE\n",
    "app_type_counts= charity_df.APPLICATION_TYPE.value_counts()  \n",
    "app_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_app_type = app_type_counts[app_type_counts <200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketing Application Type Column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace\n",
    "replace_app = list(app_type_counts[app_type_counts <200].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for APPLICATION_TYPE in replace_app:\n",
    "    charity_df.APPLICATION_TYPE = charity_df.APPLICATION_TYPE.replace(APPLICATION_TYPE,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "charity_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketing Classification Column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C1900        1\n",
       "C1236        1\n",
       "C1283        1\n",
       "C2600        1\n",
       "C3700        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in column CLASSIFICATION\n",
    "class_counts= charity_df.CLASSIFICATION.value_counts()  \n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_class = class_counts[class_counts <200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C4000    194\n",
       "C5000    116\n",
       "C1270    114\n",
       "C2700    104\n",
       "C2800     95\n",
       "        ... \n",
       "C1900      1\n",
       "C1236      1\n",
       "C1283      1\n",
       "C2600      1\n",
       "C3700      1\n",
       "Name: CLASSIFICATION, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1197\n",
       "C7000      777\n",
       "C1700      287\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bucketing  CLASSIFICATION\n",
    "# Determine which values to replace\n",
    "\n",
    "replace_app = list(class_counts[class_counts <200].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for CLASSIFICATION in replace_app:\n",
    "    charity_df.CLASSIFICATION = charity_df.CLASSIFICATION.replace(CLASSIFICATION,\"Other\")\n",
    "\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "charity_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  One Hot Encoder, Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   AFFILIATION_CompanySponsored  ...  INCOME_AMT_1-9999  \\\n",
       "0                           0.0  ...                0.0   \n",
       "1                           0.0  ...                1.0   \n",
       "2                           1.0  ...                0.0   \n",
       "3                           1.0  ...                0.0   \n",
       "4                           0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(charity_df[charity_cat1]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(charity_cat1)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0     5000              1                     0.0                   1.0   \n",
       "1   108590              1                     0.0                   0.0   \n",
       "2     5000              0                     0.0                   0.0   \n",
       "3     6692              1                     0.0                   0.0   \n",
       "4   142590              1                     0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  1.0                  0.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "charity_df = charity_df.merge(encode_df,left_index=True, right_index=True)\n",
    "charity_df = charity_df.drop(charity_cat1,1)\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target (\"Attrition\") arrays\n",
    "y = charity_df[\"IS_SUCCESSFUL\"].values\n",
    "X = charity_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Binary Classification Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 360       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer (Use sigmoid activation because predicting binary classification output - Attrition yes or no?)\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train First Model with 2 layers, 8 neurons, 5 neurons, 25 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\esobieski\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.6005 - acc: 0.7034\n",
      "Epoch 2/25\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5675 - acc: 0.7265\n",
      "Epoch 3/25\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5580 - acc: 0.7280\n",
      "Epoch 4/25\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5559 - acc: 0.7288\n",
      "Epoch 5/25\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5547 - acc: 0.7293\n",
      "Epoch 6/25\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5538 - acc: 0.7301\n",
      "Epoch 7/25\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5531 - acc: 0.7307\n",
      "Epoch 8/25\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5519 - acc: 0.7305\n",
      "Epoch 9/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5513 - acc: 0.7317\n",
      "Epoch 10/25\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5509 - acc: 0.7309\n",
      "Epoch 11/25\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5499 - acc: 0.7315\n",
      "Epoch 12/25\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5502 - acc: 0.7316\n",
      "Epoch 13/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5495 - acc: 0.7306\n",
      "Epoch 14/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5489 - acc: 0.7316\n",
      "Epoch 15/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5487 - acc: 0.7315\n",
      "Epoch 16/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5488 - acc: 0.7327\n",
      "Epoch 17/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5485 - acc: 0.7315\n",
      "Epoch 18/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5479 - acc: 0.7331\n",
      "Epoch 19/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5480 - acc: 0.7323\n",
      "Epoch 20/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5478 - acc: 0.7332\n",
      "Epoch 21/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5475 - acc: 0.7323\n",
      "Epoch 22/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5474 - acc: 0.7334\n",
      "Epoch 23/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5474 - acc: 0.7325\n",
      "Epoch 24/25\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5473 - acc: 0.7324\n",
      "Epoch 25/25\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5471 - acc: 0.7327\n"
     ]
    }
   ],
   "source": [
    "# Train the scaled model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5523 - acc: 0.7248\n",
      "Loss: 0.5523049362129789, Accuracy: 0.724781334400177\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY MORE NEURONS (48 and 8) KEEPING 2 LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 40)                1800      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,137\n",
      "Trainable params: 2,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  40\n",
    "hidden_nodes_layer2 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer (Use sigmoid activation because predicting binary classification output - Attrition yes or no?)\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train with more neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5894 - acc: 0.7145\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5555 - acc: 0.7307\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5519 - acc: 0.7294\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5503 - acc: 0.7321\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5487 - acc: 0.7329\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5479 - acc: 0.7316\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5475 - acc: 0.7331\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5468 - acc: 0.7331\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5461 - acc: 0.7335\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5460 - acc: 0.7348\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5455 - acc: 0.7343\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5448 - acc: 0.73470s - loss: 0.5506\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5451 - acc: 0.7339\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5448 - acc: 0.7348\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5440 - acc: 0.7350\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5441 - acc: 0.7350\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5441 - acc: 0.7357\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5436 - acc: 0.7339\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5435 - acc: 0.7351\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5430 - acc: 0.7357\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5425 - acc: 0.7367\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5428 - acc: 0.7370\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5428 - acc: 0.7357\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5427 - acc: 0.7368\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.5423 - acc: 0.7358\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5418 - acc: 0.7375\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5418 - acc: 0.7371\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5414 - acc: 0.7382\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5412 - acc: 0.7378\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5414 - acc: 0.7374\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5412 - acc: 0.7369\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5409 - acc: 0.7376\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5409 - acc: 0.7376\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5408 - acc: 0.7365\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5410 - acc: 0.7385\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5409 - acc: 0.7381\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5405 - acc: 0.7383\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5401 - acc: 0.7378\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5407 - acc: 0.7383\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5402 - acc: 0.7396\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5401 - acc: 0.7374\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5398 - acc: 0.7381\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5403 - acc: 0.7381\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5398 - acc: 0.7379\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5398 - acc: 0.7378\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5396 - acc: 0.7390\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5398 - acc: 0.7384\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5394 - acc: 0.7386\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5393 - acc: 0.7392\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5398 - acc: 0.7389\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5540 - acc: 0.7271\n",
      "Loss: 0.5540025636962135, Accuracy: 0.7271137237548828\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY LESS LAYERS AND 48 NEURONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 48)                2160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 2,209\n",
      "Trainable params: 2,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  48\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Output layer (Use sigmoid activation because predicting binary classification output - Attrition yes or no?)\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train with Less Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5796 - acc: 0.7170\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5575 - acc: 0.72940s - loss: 0.565\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5530 - acc: 0.7317\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5521 - acc: 0.7317\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5506 - acc: 0.7318\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5489 - acc: 0.7322\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5487 - acc: 0.7312\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5482 - acc: 0.7323\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5476 - acc: 0.7320\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5480 - acc: 0.7331\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5470 - acc: 0.7332\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5468 - acc: 0.7333\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 29us/sample - loss: 0.5461 - acc: 0.7342\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5464 - acc: 0.7343\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5461 - acc: 0.7333\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5459 - acc: 0.7344\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5453 - acc: 0.7335\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5451 - acc: 0.7342\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5447 - acc: 0.7352\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5451 - acc: 0.7331\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 1s 29us/sample - loss: 0.5447 - acc: 0.7351\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 1s 29us/sample - loss: 0.5449 - acc: 0.7338\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5452 - acc: 0.7350\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 1s 29us/sample - loss: 0.5443 - acc: 0.7355\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5440 - acc: 0.7341\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5447 - acc: 0.7345\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5445 - acc: 0.7333\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5439 - acc: 0.7346\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5438 - acc: 0.7351\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5437 - acc: 0.7338\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5435 - acc: 0.7347\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5432 - acc: 0.7361\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5433 - acc: 0.7356\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5429 - acc: 0.7352\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5427 - acc: 0.7345\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5426 - acc: 0.7353\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5423 - acc: 0.7355\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5422 - acc: 0.7364\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5425 - acc: 0.7355\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 1s 29us/sample - loss: 0.5423 - acc: 0.7357\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5425 - acc: 0.7362\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5424 - acc: 0.7353\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5422 - acc: 0.7357\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5421 - acc: 0.7362\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 1s 29us/sample - loss: 0.5420 - acc: 0.7371\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5418 - acc: 0.7374\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5416 - acc: 0.7355\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5419 - acc: 0.7368\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5416 - acc: 0.7358\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5414 - acc: 0.7358\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5544 - acc: 0.7248\n",
      "Loss: 0.5543982881359735, Accuracy: 0.724781334400177\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Input Activation Function using First Model (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 8)                 360       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Output layer (Use sigmoid activation because predicting binary classification output - Attrition yes or no?)\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.6030 - acc: 0.6953\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5665 - acc: 0.7272\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5599 - acc: 0.7297\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5563 - acc: 0.7314\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5541 - acc: 0.7315\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5526 - acc: 0.7327\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5518 - acc: 0.7325\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5509 - acc: 0.7324\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5503 - acc: 0.7336\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5493 - acc: 0.7341\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5489 - acc: 0.7330\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5484 - acc: 0.7335\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5481 - acc: 0.7339\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5481 - acc: 0.7339\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5478 - acc: 0.7339\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5474 - acc: 0.7340\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5471 - acc: 0.7329\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5469 - acc: 0.7336\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5467 - acc: 0.7342\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5466 - acc: 0.7340\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5465 - acc: 0.7347\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5461 - acc: 0.7341\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5459 - acc: 0.7348\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5456 - acc: 0.7346\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5455 - acc: 0.7345\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 30us/sample - loss: 0.5449 - acc: 0.7355\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5450 - acc: 0.7354\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5449 - acc: 0.7352\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5448 - acc: 0.7351\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5445 - acc: 0.7353\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5445 - acc: 0.7353\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5442 - acc: 0.7358\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5444 - acc: 0.7354\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5442 - acc: 0.7363\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5440 - acc: 0.7355\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5442 - acc: 0.7364\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5439 - acc: 0.7356\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5440 - acc: 0.7352\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5439 - acc: 0.7351\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5439 - acc: 0.7353\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5438 - acc: 0.7359\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5435 - acc: 0.7366\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5434 - acc: 0.7357\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5434 - acc: 0.7365\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5432 - acc: 0.7360\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5433 - acc: 0.7364\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5431 - acc: 0.7365\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5432 - acc: 0.7368\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5432 - acc: 0.7363\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5432 - acc: 0.7363\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5526 - acc: 0.7258\n",
      "Loss: 0.5525708128411986, Accuracy: 0.7258309125900269\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train first model, 2 layers, 8 and 5 neurons, with 50 epochs vs 25 first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 8)                 360       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer (Use sigmoid activation because predicting binary classification output - Attrition yes or no?)\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.6235 - acc: 0.6807\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5656 - acc: 0.7262\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5600 - acc: 0.7283\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5565 - acc: 0.7278\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5551 - acc: 0.7294\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5535 - acc: 0.7296\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5531 - acc: 0.7301\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 33us/sample - loss: 0.5519 - acc: 0.7303\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5514 - acc: 0.7309\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5513 - acc: 0.7304\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5505 - acc: 0.7308\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5502 - acc: 0.7302\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5498 - acc: 0.7315\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5496 - acc: 0.7312\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5495 - acc: 0.7313\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5488 - acc: 0.7323\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5486 - acc: 0.7318\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 32us/sample - loss: 0.5482 - acc: 0.7314\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 1s 31us/sample - loss: 0.5483 - acc: 0.7309\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.5480 - acc: 0.7321\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5474 - acc: 0.7309\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5473 - acc: 0.7328\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5472 - acc: 0.7326\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.5471 - acc: 0.7316\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5471 - acc: 0.7323\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5470 - acc: 0.7319\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5470 - acc: 0.7320\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5470 - acc: 0.7327\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5465 - acc: 0.7326\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5464 - acc: 0.7332\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5464 - acc: 0.7328\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5464 - acc: 0.7331\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5462 - acc: 0.7338\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5461 - acc: 0.7329\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5460 - acc: 0.7329\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5457 - acc: 0.7336\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5455 - acc: 0.7331\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5456 - acc: 0.7338\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5457 - acc: 0.7325\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5456 - acc: 0.7332\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5453 - acc: 0.7338\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5454 - acc: 0.7350\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5453 - acc: 0.7342\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5455 - acc: 0.7344\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5455 - acc: 0.7337\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5453 - acc: 0.7338\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 34us/sample - loss: 0.5453 - acc: 0.7344\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 35us/sample - loss: 0.5452 - acc: 0.7341\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.5448 - acc: 0.7352\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5451 - acc: 0.7336\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5508 - acc: 0.7259\n",
      "Loss: 0.5508177991094116, Accuracy: 0.7259474992752075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
